1.1 Пропуски имеют признаки first_blood_time, first_blood_team, first_blood_player1, first_blood_player2, radiant_bottle_time, radiant_courier_time, radiant_flying_courier_time, radiant_first_ward_time, dire_bottle_time, dire_courier_time, dire_flying_courier_time, dire_first_ward_time
Как правило, пропуски означают, что одно из событий не успело произойти за первые 5 минут матча - например, никто в команде Radiant не приобрел bottle (radiant_bottle_time), или за 5 минут стороны так и не вступили в бой друг с другом (first_blood_time).

1.2 Целевую переменную содержит столбец radiant_win, поскольку в конечном итоге нам надо предсказать, кто победит в матче.
1.3 Для градиентного бустинга с 30 деревьями кросс-валидация проводилась 169 секунд, качество при разных learning_rate получилось  от 0,69799 до 0,70279.
1.4 На мой взгляд, особого смысла в увеличении количества деревьев нет, так как качество растет максимум на десятые доли процента при том, что время работы алгоритма существенно увеличивается при увеличении количества деревьев, в среднем в 2 раза при каждом увеличении числа деревьев на 10 штук. Ниже приведена сводная таблица:
Кол-во деревьев	Learning rate 	Качество		Время работы
10 					0.5 		0.685289500154 	0:01:10.424743
10 					0.3 		0.683910651898 	0:00:58.759696
10 					0.2 		0.677808604174 	0:00:57.552219
20 					0.5 		0.697754399312 	0:01:51.645483
20 					0.3 		0.695695647322 	0:01:58.847733
20 					0.2 		0.691567016024 	0:02:03.391514
30 					0.5 		0.702798542829 	0:02:59.975838
30 					0.3 		0.701110820367 	0:02:52.259412
30 					0.2 		0.697991521064 	0:02:49.354217
40 					0.5 		0.706125695438 	0:03:45.106205
40 					0.3 		0.704531584654 	0:03:54.368167
40 					0.2 		0.702197446648 	0:03:46.364233
Для ускорения можно продумать варианты с уменьшением обучающей выборки, отбрасыванием лишних признаков (например, время матча, которое, если рассуждать логически, не должно являться важным признаком при определении исхода матча - даже отбрасывание одного признака снижает время обучения на 2-8 секунд).



2.1 Качество логистической регрессии оказалось чуть получше (на 1%, см. ниже) при том, что алгоритм обучается гораздо быстрее, чем градиентный бустинг. Сравнимое с бустингом качество можно объяснить тем, что бустинг в целом довольно неплохой алгоритм для получения первичного решения без дополнительной обработки и фильтрации данных и признаков. При этом логистическая регрессия достигает сопоставимого качество лишь после нормализации признаков - без нормализации признаков качество работы алгоритма колеблется в районе 0,51-0.53.
C 					 Качество				 Время
1e-05 				 0.695177098262 		 0:00:03.830890
0.0001 				 0.711286512716 		 0:00:05.731635
0.001 				 0.71620963601 		  	 0:00:10.081176
0.01 				 0.716375794854 		 0:00:13.171028
0.1 				 0.716350926752 		 0:00:14.131998
1.0 				 0.71634726819 		 	 0:00:13.943376
10.0 				 0.716347073498 		 0:00:14.194942
100.0 				 0.716347076705 		 0:00:13.792157
1000.0 				 0.716347089423 		 0:00:14.122834
10000.0 			 0.716347101075 		 0:00:13.827702

Из таблицы видно, что увеличение коэффициента С больше 0.01 не приводит к улучшению качества, а лишь приводит к увеличению времени работы алгоритма.

2.2 После удаление категориальных признаков качество работы алгоритма практически не изменилось (при С=0,01 до удаления было 0.716375794854, после стало 0.716408868155), при этом алгоритм стал работать чуть быстрее. Объяснить это можно тем, что и до удаления категориальные признаки практичеки не влияли на качество - если посмотреть на их веса, полученные после обучения алгоритма, (в переменной clf.coef_), то видно, что веса, соответствующие категориальным признакам, в среднем на порядок меньше остальных весов.

2.3 Всего в наборе данных присутствует 108 героев

2.4 Да, после добавления вместо категориальных признаков мешка, построенного на их основе, качество увеличилось с 0.716375794854 до 0.751904730598. Это произошло в основном благодаря тому, что при после построения мешка признаков "расстояние" стало считаться более корректно и мы фактически при построении модели стали учитывать не просто номер игрока, но факт его участия в победных играх

2.5 Минимальное и максимальное значения прогноза на тестовой выборке для алгоритма с наилучшими параметрами равны 0.00870590076923 и 0.996328715925, соответственно

2.5
